{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning & Deep Learning\n",
    "\n",
    "머신러닝과 딥러닝 공통점 : 파라미터가 모델의 학습 대상이 되는 것\n",
    "\n",
    "딥러닝 : 뉴런들 스택을 쌓아나가는 것을 딥러닝 모델이라고 할 수 있다. \n",
    "\n",
    "머신러닝과 딥러닝에서의 '러닝'은 결국 모델의 파라미터 학습을 의미한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "### Regression vs Classification\n",
    "\n",
    "- regression --> 예측하고자 하는 값이 continous\n",
    "\n",
    "- classification --> 예측하고자 하는 값이 discrete. 연속적인 값도 discrete하게 만든다.\n",
    "\n",
    "\n",
    "Linear Regression --> y = ax 형태. 나중에 non-linear도 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss vs Cost\n",
    "\n",
    "함께 쓰이기도 하나 엄밀하게 차이를 정의하면\n",
    "\n",
    "\n",
    "- loss: 각 데이터(datapoint)에 대해서의 예측값과 실제값의 차이 (하나의 datapoint 관련)\n",
    "- cost : 전체 데이터에 대한 실제값(y값)과 예측값들과의 차이 평균 (전체 data 관련)\n",
    "\n",
    "\n",
    "\n",
    "--> 구분한 이유 : 이후 backprogation 때 따로 구분될 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "#### Learning Rate : cost function 에서 얼만큼 theta 값을 이동할지\n",
    "\n",
    "(1) J : cost function. MSE (Mean Square Error). \n",
    "(2) θ = θ - a (cost function / θ) (즉 기울기) <-- 에서의 a 가 learning rate (일반적으로 alpha로 표현)\n",
    "\n",
    "- 위 (1)과 theta를 업데이트하는 (2)까지 이 과정이 하나의 iteration.\n",
    "\n",
    "\n",
    "\n",
    "learning rate 가 \n",
    "\n",
    "(1) 너무 클 경우 : 발산. 튕겨나갈 위험이 있다.\n",
    "\n",
    "(2) 너무 작을 경우 : 너무 느림\n",
    "\n",
    "(3) 애매하게 작은 경우 : 지그재그하며 내려옴, But 조금이라도 커지면 발산할 위험이 있다는 의미.\n",
    "\n",
    "(4) 적당한 경우 : 슬슬 내려와 수렴하는 것.\n",
    "\n",
    "tip: iteration 을 체크할 때 홀수로 하는 것을 추천!\n",
    "\n",
    "    --> 홀수로 해야 지그재그로 수렴하는지 아니면 한 방향으로 쭉 내려오는지 확인할 수 있음.\n",
    "    \n",
    "    --> 만약에 짝수로 할 경우 '왔다 갔다' 에서 '왔다'만 확인할 수 있게 되기 때문에 이 learning rate를 홀수로 하는 것 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tip: learning rate은 3배 단위로 잡는것이 일반적 (0.001, 0.003, 0.01, 0.03, 0.1 이런식)\n",
    "\n",
    "tip: learning rate를 크게 잡고, 가다가 작게 다시 조정하면 더 정확한 결과를 얻을 수 있지만 사실 현실적으로 쉽지 않다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
